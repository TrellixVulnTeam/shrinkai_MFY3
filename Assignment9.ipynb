{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "pytorch",
      "display_name": "pytorch"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cejx5xaJH6G",
        "colab_type": "text"
      },
      "source": [
        "# Cloning <a  href='https://github.com/nikshrimali/shrinkai'>SHRINKai</a>"
      ]
    },
    {
      "source": [
        "# Things to do\n",
        "- Add albumations augmentation - Done\n",
        "- Add LR finder - Done\n",
        "- Add model save features into shrink - Done\n",
        "- Add 25 misclassified images grid to shrink\n",
        "- Add view dataset to shrink\n",
        "- Apply cutout and guassian noise to the program - Done\n",
        "- Add logs to the code"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39t2TNs7EYCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "101280da-86c5-41fe-fd34-44c6dcde2ba3",
        "tags": []
      },
      "source": [
        "# Cloning shrinkai\n",
        "# !git clone https://github.com/nikshrimali/shrinkai"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_RUchliJB-_",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKulaUm9Hriq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "9e278abf-7a0e-446b-f83b-68a1f3645588",
        "tags": []
      },
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "from model.model_test import model_testing\n",
        "from model.model_train import model_training\n",
        "\n",
        "from data_process.getdata import GetCIFAR10_TrainData\n",
        "from data_process.misclassified_data import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "# print(os.getcwd())\n",
        "from model.gradcam import gen_gradcam\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch_lr_finder import LRFinder\n",
        "except ImportError:\n",
        "    # Run from source\n",
        "    import sys\n",
        "    sys.path.insert(0, '..')\n",
        "    from torch_lr_finder import LRFinder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "cuda\n"
        }
      ]
    },
    {
      "source": [
        "# Config File"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting cifar.yml\n"
        }
      ],
      "source": [
        "%%writefile cifar.yml\n",
        "name: CIFAR10_MyNet\n",
        "save_dir: saved/\n",
        "seed: 1\n",
        "target_device: 0\n",
        "\n",
        "arch:\n",
        "    type: CIFAR10_S9Model\n",
        "    args: {}\n",
        "\n",
        "train_augmentations:\n",
        "    type: alb_train\n",
        "    args:\n",
        "        [ #resises the image so it can be perfect for our model.\n",
        "            transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
        "            transforms.RandomRotation(10),     #Rotates the image to a specified angel\n",
        "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
        "            transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
        "            transforms.Normalize(self.mean, self.std) #Normalize all the images\n",
        "            ]\n",
        "\n",
        "        # A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5), \n",
        "        # A.RandomCrop(height=32, width=32),\n",
        "        # A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
        "        # A.RandomBrightnessContrast(p=0.5),\n",
        "        # A.GaussNoise(),\n",
        "        # A.ElasticTransform(),\n",
        "        # A.Cutout(p=1),\n",
        "        # A.Normalize(mean=(0.491, 0.482, 0.446), std=(0.247, 0.243, 0.261)),\n",
        "        # A.ToTensorV2(),\n",
        "\n",
        "test_augmentations:\n",
        "    type: alb_test\n",
        "    args:\n",
        "        A.Normalize(mean=(0.491, 0.482, 0.446), std=(0.247, 0.243, 0.261)),\n",
        "        A.ToTensorV2()\n",
        "\n",
        "data_loader:\n",
        "    type: CIFAR10DataLoader\n",
        "    args:\n",
        "        batch_size: 128\n",
        "        data_dir: data/\n",
        "        nworkers: 4\n",
        "        shuffle: True\n",
        "\n",
        "criterion: cross_entropy_loss\n",
        "\n",
        "lr_scheduler:\n",
        "    type: OneCycleLR\n",
        "    args:\n",
        "        max_lr: 0.1\n",
        "\n",
        "optimizer:\n",
        "    type: SGD\n",
        "    args:\n",
        "        lr: 0.001\n",
        "        momentum: 0.95\n",
        "        weight_decay: 0.0005\n",
        "\n",
        "training:\n",
        "    epochs: 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "filename = \"cifar.yml\"\n",
        "with open(filename) as fh:\n",
        "    config = yaml.safe_load(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Files already downloaded and verified\nFiles already downloaded and verified\n"
        }
      ],
      "source": [
        "from data_process.albumentation import *\n",
        "\n",
        "trainset = datasets.CIFAR10('./data', train=True, download=True, transform=cifar_alb_trainData())\n",
        "testset = datasets.CIFAR10('./data', train=False, download=True, transform=cifar_alb_testdata())\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # Get the dataloaders\n",
        "\n",
        "# from data_process.albumentation import *\n",
        "\n",
        "# train_albs = cifar_alb_trainData()\n",
        "# test_albs = cifar_alb_testdata()\n",
        "# trainloader = get_cifar_loaders(train_albs)\n",
        "# testloader = get_cifar_loaders(test_albs, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Grid showing images of the dataset - before and after transformations\n",
        "\n",
        "def display_image_grid(images_filepaths, predicted_labels=(), cols=5):\n",
        "    rows = len(images_filepaths) // cols\n",
        "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
        "    for i, image_filepath in enumerate(images_filepaths):\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        true_label = os.path.normpath(image_filepath).split(os.sep)[-2]\n",
        "        predicted_label = predicted_labels[i] if predicted_labels else true_label\n",
        "        color = \"green\" if true_label == predicted_label else \"red\"\n",
        "        ax.ravel()[i].imshow(image)\n",
        "        ax.ravel()[i].set_title(predicted_label, color=color)\n",
        "        ax.ravel()[i].set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZFXAW9CI5yt",
        "colab_type": "text"
      },
      "source": [
        "# Importing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pul6T5YZHyjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aea37f08-e580-4514-c65b-d57da6301d9b",
        "tags": []
      },
      "source": [
        "from model.resnetmodel8 import ResNet18\n",
        "model = ResNet18().to(device)\n",
        "summary(model, input_size=(3,32,32))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n            Conv2d-3           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-4           [-1, 64, 32, 32]             128\n           Dropout-5           [-1, 64, 32, 32]               0\n            Conv2d-6           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-7           [-1, 64, 32, 32]             128\n           Dropout-8           [-1, 64, 32, 32]               0\n        BasicBlock-9           [-1, 64, 32, 32]               0\n           Conv2d-10           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-11           [-1, 64, 32, 32]             128\n          Dropout-12           [-1, 64, 32, 32]               0\n           Conv2d-13           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-14           [-1, 64, 32, 32]             128\n          Dropout-15           [-1, 64, 32, 32]               0\n       BasicBlock-16           [-1, 64, 32, 32]               0\n           Conv2d-17          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-18          [-1, 128, 16, 16]             256\n          Dropout-19          [-1, 128, 16, 16]               0\n           Conv2d-20          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-21          [-1, 128, 16, 16]             256\n          Dropout-22          [-1, 128, 16, 16]               0\n           Conv2d-23          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-24          [-1, 128, 16, 16]             256\n          Dropout-25          [-1, 128, 16, 16]               0\n       BasicBlock-26          [-1, 128, 16, 16]               0\n           Conv2d-27          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-28          [-1, 128, 16, 16]             256\n          Dropout-29          [-1, 128, 16, 16]               0\n           Conv2d-30          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-31          [-1, 128, 16, 16]             256\n          Dropout-32          [-1, 128, 16, 16]               0\n       BasicBlock-33          [-1, 128, 16, 16]               0\n           Conv2d-34            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-35            [-1, 256, 8, 8]             512\n          Dropout-36            [-1, 256, 8, 8]               0\n           Conv2d-37            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-38            [-1, 256, 8, 8]             512\n          Dropout-39            [-1, 256, 8, 8]               0\n           Conv2d-40            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-41            [-1, 256, 8, 8]             512\n          Dropout-42            [-1, 256, 8, 8]               0\n       BasicBlock-43            [-1, 256, 8, 8]               0\n           Conv2d-44            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-45            [-1, 256, 8, 8]             512\n          Dropout-46            [-1, 256, 8, 8]               0\n           Conv2d-47            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-48            [-1, 256, 8, 8]             512\n          Dropout-49            [-1, 256, 8, 8]               0\n       BasicBlock-50            [-1, 256, 8, 8]               0\n           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n          Dropout-53            [-1, 512, 4, 4]               0\n           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n          Dropout-56            [-1, 512, 4, 4]               0\n           Conv2d-57            [-1, 512, 4, 4]         131,072\n      BatchNorm2d-58            [-1, 512, 4, 4]           1,024\n          Dropout-59            [-1, 512, 4, 4]               0\n       BasicBlock-60            [-1, 512, 4, 4]               0\n           Conv2d-61            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-62            [-1, 512, 4, 4]           1,024\n          Dropout-63            [-1, 512, 4, 4]               0\n           Conv2d-64            [-1, 512, 4, 4]       2,359,296\n      BatchNorm2d-65            [-1, 512, 4, 4]           1,024\n          Dropout-66            [-1, 512, 4, 4]               0\n       BasicBlock-67            [-1, 512, 4, 4]               0\n           Linear-68                   [-1, 10]           5,130\n================================================================\nTotal params: 11,173,962\nTrainable params: 11,173,962\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 15.44\nParams size (MB): 42.63\nEstimated Total Size (MB): 58.07\n----------------------------------------------------------------\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcVMHoYTJe55",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#  Downloading the dataset and applying transformations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQqcD6G7Jlw3",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "source": [
        "# Finding the optimal LR\n",
        "- Leslie Smith's Approach\n",
        "- Fast.ai Approach\n",
        "\n",
        "Lets try implementing both of them"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Leslie Smith's Approach\n",
        "Increases the learning rate linearly and computes the evaluation loss for each learning rate.\n",
        "Params - Number of iterations - The value is optimal when is 2-10 times the no of iterations in each epoch\n",
        "\n",
        "### How to select the no of iterations of each epoch?\n",
        "    Each Epoch has 391 iterations we will multiply this by 4 hence 391*4 = 1564\n",
        "\n",
        "### How to select the boundary values of LR?\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## Fast.ai Approach\n",
        "Increases the learning rate in an exponential manner and computes the training loss for each learning rate."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ68Gzm-IFIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51ea65cc-bee4-4fe2-ad54-ad00d93cb046",
        "tags": []
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.05, patience=2, threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n",
        "scheduler = StepLR(optimizer, step_size=25, gamma=0.1)\n",
        "\n",
        "train_acc = []\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "test_losses = []\n",
        "EPOCHS = 20\n",
        "model_path = 'latest_model.h5'\n",
        "\n",
        "import os\n",
        "\n",
        "print(f'Starting Training for {EPOCHS} Epochs')\n",
        "try:\n",
        "    os.remove(model_path) # deleting the existing file\n",
        "except:\n",
        "    pass\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    print(f'EPOCHS : {i}')\n",
        "    model_training(model, device, trainloader, optimizer, train_acc, train_losses, l1_loss=False)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    scheduler.step()\n",
        "    misclassified = model_testing(model, device, testloader, test_acc, test_losses)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/391 [00:00&lt;?, ?it/s]Starting Training for 20 Epochs\nEPOCHS : 0\nLoss=2.3147592544555664 Batch_id=12 Accuracy=13.40:   3%|▎         | 13/391 [00:06&lt;03:17,  1.92it/s]\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m&lt;ipython-input-9-37227f755ccf&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf&#39;EPOCHS : {i}&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 23\u001b[1;33m     \u001b[0mmodel_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Python Projects\\shrinkai\\model\\model_train.py\u001b[0m in \u001b[0;36mmodel_training\u001b[1;34m(model, device, train_dataloader, optimizer, train_acc, train_losses, l1_loss)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-&gt; 1129\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m&lt;listcomp&gt;\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 113\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Python Projects\\shrinkai\\data_process\\albumentation.py\u001b[0m in \u001b[0;36m&lt;lambda&gt;\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtransforms_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtransforms_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m&quot;image&quot;\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, **data)\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 176\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdual_start_end\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdual_start_end\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m                 )\n\u001b[0;32m     77\u001b[0m                 \u001b[0mtargets_as_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets_as_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 78\u001b[1;33m                 \u001b[0mparams_dependent_on_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params_dependent_on_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_as_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dependent_on_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Python\\envs\\pytorch\\lib\\site-packages\\albumentations\\augmentations\\transforms.py\u001b[0m in \u001b[0;36mget_params_dependent_on_targets\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m   2572\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-&gt; 2574\u001b[1;33m         \u001b[0mgauss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2575\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m&quot;gauss&quot;\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgauss\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'latest_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[42.76, 52.27, 49.35]\n"
        }
      ],
      "source": [
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYRArZkVJw5C",
        "colab_type": "text"
      },
      "source": [
        "# Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3_3JQWuZThK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95a3406c-4622-4195-d1b5-d7add9daf942"
      },
      "source": [
        "\n",
        "# fig, axs = plt.plot(figsize=(25,20))\n",
        "\n",
        "# # axs[0,0].set_title('Train Losses')\n",
        "# axs[0,0].set_title('Training and Test Accuracy')\n",
        "# # axs[1,0].set_title('Test Losses')\n",
        "# # axs[1,1].set_title('Test Accuracy')\n",
        "\n",
        "# # axs[0,0].plot(train_losses)\n",
        "# axs[0,0].plot(train_acc)\n",
        "# # axs[1,0].plot(test_losses)\n",
        "# axs[0,0].plot(test_acc)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 0)",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m&lt;ipython-input-10-996e305f7537&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[1;32m----&gt; 1\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# axs[0,0].set_title(&#39;Train Losses&#39;)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&#39;Training and Test Accuracy&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# axs[1,0].set_title(&#39;Test Losses&#39;)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[&lt;matplotlib.lines.Line2D at 0x1ca41712b88&gt;]"
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "&lt;Figure size 432x288 with 1 Axes&gt;",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 248.518125 \r\nL 368.925 248.518125 \r\nL 368.925 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 361.725 224.64 \r\nL 361.725 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m68d76e3f98\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.00 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(31.010369 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"80.188636\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 0.25 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(69.055824 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.234091\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 0.50 -->\r\n      <g transform=\"translate(107.101278 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.279545\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0.75 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(145.146733 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.325\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 1.00 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(183.192188 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.370455\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 1.25 -->\r\n      <g transform=\"translate(221.237642 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"270.415909\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 1.50 -->\r\n      <g transform=\"translate(259.283097 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"308.461364\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 1.75 -->\r\n      <g transform=\"translate(297.328551 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"346.506818\" xlink:href=\"#m68d76e3f98\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 2.00 -->\r\n      <g transform=\"translate(335.374006 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_10\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m336269ca44\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m336269ca44\" y=\"216.555782\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 220.355001)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m336269ca44\" y=\"179.982232\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 183.78145)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m336269ca44\" y=\"143.408681\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 35 -->\r\n      <g transform=\"translate(7.2 147.2079)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m336269ca44\" y=\"106.83513\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 110.634349)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m336269ca44\" y=\"70.261579\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 45 -->\r\n      <g transform=\"translate(7.2 74.060798)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m336269ca44\" y=\"33.688028\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(7.2 37.487247)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p51f29b26fc)\" d=\"M 42.143182 214.756364 \r\nL 194.325 169.536825 \r\nL 346.506818 141.492227 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p51f29b26fc)\" d=\"M 42.143182 86.64653 \r\nL 194.325 17.083636 \r\nL 346.506818 38.44259 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 361.725 224.64 \r\nL 361.725 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 361.725 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 361.725 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p51f29b26fc\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name &#39;AugmentationFactoryBase&#39; is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m&lt;ipython-input-10-8b577b1fd71c&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[1;32m----&gt; 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_gradcam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m&#39;plane&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;car&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;bird&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;cat&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;deer&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;dog&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;frog&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;horse&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;ship&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&#39;truck&#39;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtarget_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m&quot;layer1&quot;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&quot;layer2&quot;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&quot;layer3&quot;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&quot;layer4&quot;\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.491\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.482\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.446\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Python Projects\\shrinkai\\model\\gradcam\\utils.py\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Applying Albumentations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---&gt; 55\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mCIFAR10Albumentations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAugmentationFactoryBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.4914\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4822\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4465\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name &#39;AugmentationFactoryBase&#39; is not defined"
          ]
        }
      ],
      "source": [
        "from model.gradcam.utils import plot_gradcam\n",
        "\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "target_layers = [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]\n",
        "mean = (0.491, 0.482, 0.446)\n",
        "std = (0.247, 0.243, 0.261)\n",
        "\n",
        "plot_gradcam(target_layers, device, testloader, model, mean, std, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_augmentations(dataset, idx=0, samples=10, cols=5):\n",
        "    dataset = copy.deepcopy(dataset)\n",
        "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
        "    rows = samples // cols\n",
        "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
        "    for i in range(samples):\n",
        "        image, _ = dataset[idx]\n",
        "        ax.ravel()[i].imshow(image)\n",
        "        ax.ravel()[i].set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "&#39;nvidia-smi&#39; is not recognized as an internal or external command,\noperable program or batch file.\n"
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    }
  ]
}